server.port=5080
local.server.port=5080
kafka.bootstrapAddress=localhost:9092
kafka.topicName=test
kafka.partition.count=1
kafka.replicaset.count=1
kafka.consumer.groupid=testGroup



#    //zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties
#    //kafka-topics --create --topic test --zookeeper localhost:2181 --partitions 3 --replication-factor 2
#    //kafka-topics --describe --topic test_topic --zookeeper localhost:2181
#    //kafka-console-producer --broker-list localhost:9092 --topic test
#    //kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning
#    //kafka-topics --alter --topic test --zookeeper localhost:2181 --partitions 3 --replication-factor 2
#    //kafka-topics --delete --topic test --zookeeper localhost:2181
#    //kafka-topics --list --zookeeper localhost:2181

# https://intellipaat.com/community/43827/what-is-zookeeper-in-kafka
#
# Max number of message size possible in kafka -> by default 1MB
# Where Topic messages are persisted -> on disk in kafka logs
# How can we make the data processing in kafka sequentially ? -> Kafka by default maintains the sequence in each partition.
# How can we make the data processing in kafka sequentially ? -> Make a mapping of kafka topic partition to only one consumer and push one sequence of data to only one partition.
#                                                               For more if data publishing and consuming is asynchronous then set one data id for a sequence of data.
#                                                               For example for a data sequence set data id as 1 and one a consumer receives a data first message it will
#                                                               just put a data in common global cache and take a lock on it so that no other consumer will consume subsequent messages
#                                                               but in the case when sequence of messages are at high frequency for example each message is getting published at every nano second
#                                                               then this consumer based approach would may fail under multi-threaded scenario (https://www.cloudkarafka.com/blog/2018-08-21-faq-apache-kafka-strict-ordering.html).
#
# Leader Follower pattern ->
#                       https://stackoverflow.com/questions/3058272/explain-leader-follower-pattern
#                       As you might have read, the pattern consists of 4 components: ThreadPool, HandleSet, Handle, ConcreteEventHandler (implements the EventHandler interface).
#                       You can think of it as a taxi station at night, where all the drivers are sleeping except for one, the leader. The ThreadPool is a station managing many threads - cabs.
#                       The leader is waiting for an IO event on the HandleSet, like how a driver waits for a client.
#                       When a client arrives (in the form of a Handle identifying the IO event), the leader driver wakes up another driver to be the next leader and serves the request from his passenger.
#                       While he is taking the client to the given address (calling ConcreteEventHandler and handing over Handle to it) the next leader can concurrently serve another passenger.
#                       When a driver finishes he take his taxi back to the station and falls asleep if the station is not empty. Otherwise he become the leader.
#
#                       The pros for this pattern are:
#                       no communication between the threads are necessary, no synchronization, nor shared memory (no locks, mutexes) are needed.
#                       more ConcreteEventHandlers can be added without affecting any other EventHandler
#                       minimizes the latency because of the multiple threads
#
#                       The cons are:
#                       complex
#                       network IO can be a bottleneck
#
# Role of zookeeper -> Zookeeper keeps track of status of the Kafka cluster nodes and it also keeps track of Kafka topics, partitions etc.
#                      Zookeeper it self is allowing multiple clients to perform simultaneous reads and writes and acts as a shared configuration service within the system.
#                      https://data-flair.training/blogs/zookeeper-in-kafka/
#
# Can you run kafka without zookeeper -> No
